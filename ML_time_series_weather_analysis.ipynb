{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Time Series Data: Predict Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Time series prediction presents its own challenges which are different from machine-learning problems.  As with many other classes of problems, there are a number of common features in these predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## A note on scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "It **is** possible to score >1 on these questions. This indicates that you've beaten our reference model - we compare our model's score on a test set to your score on a test set. See how high you can go!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Fetch the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The data can be loaded into pandas easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th>temp</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>precip_hour</th>\n",
       "      <th>weather_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2010-01-01 00:51</td>\n",
       "      <td>62.06</td>\n",
       "      <td>15.98</td>\n",
       "      <td>1024.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2010-01-01 01:51</td>\n",
       "      <td>60.08</td>\n",
       "      <td>17.96</td>\n",
       "      <td>1025.30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2010-01-01 02:51</td>\n",
       "      <td>59.00</td>\n",
       "      <td>17.96</td>\n",
       "      <td>1025.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2010-01-01 03:51</td>\n",
       "      <td>53.96</td>\n",
       "      <td>21.92</td>\n",
       "      <td>1026.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2010-01-01 04:51</td>\n",
       "      <td>55.94</td>\n",
       "      <td>17.06</td>\n",
       "      <td>1026.20</td>\n",
       "      <td>5.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392131</th>\n",
       "      <td>NYC</td>\n",
       "      <td>2018-12-31 19:51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>37.90</td>\n",
       "      <td>1024.10</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392132</th>\n",
       "      <td>NYC</td>\n",
       "      <td>2018-12-31 20:51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>37.90</td>\n",
       "      <td>1023.40</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392133</th>\n",
       "      <td>NYC</td>\n",
       "      <td>2018-12-31 21:51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>39.90</td>\n",
       "      <td>1021.60</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.04</td>\n",
       "      <td>RA BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392134</th>\n",
       "      <td>NYC</td>\n",
       "      <td>2018-12-31 22:51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1020.90</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.05</td>\n",
       "      <td>RA BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392135</th>\n",
       "      <td>NYC</td>\n",
       "      <td>2018-12-31 23:51</td>\n",
       "      <td>44.10</td>\n",
       "      <td>42.10</td>\n",
       "      <td>1019.70</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.09</td>\n",
       "      <td>RA BR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392136 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       station              time   temp dew_point pressure wind_speed  \\\n",
       "0          PHX  2010-01-01 00:51  62.06     15.98  1024.90       3.00   \n",
       "1          PHX  2010-01-01 01:51  60.08     17.96  1025.30       4.00   \n",
       "2          PHX  2010-01-01 02:51  59.00     17.96  1025.60       4.00   \n",
       "3          PHX  2010-01-01 03:51  53.96     21.92  1026.00       0.00   \n",
       "4          PHX  2010-01-01 04:51  55.94     17.06  1026.20       5.00   \n",
       "...        ...               ...    ...       ...      ...        ...   \n",
       "392131     NYC  2018-12-31 19:51  43.00     37.90  1024.10          M   \n",
       "392132     NYC  2018-12-31 20:51  43.00     37.90  1023.40          M   \n",
       "392133     NYC  2018-12-31 21:51  43.00     39.90  1021.60          M   \n",
       "392134     NYC  2018-12-31 22:51  43.00     41.00  1020.90          M   \n",
       "392135     NYC  2018-12-31 23:51  44.10     42.10  1019.70          M   \n",
       "\n",
       "       wind_direction precip_hour weather_codes  \n",
       "0               20.00           M             M  \n",
       "1               50.00           M             M  \n",
       "2               30.00           M             M  \n",
       "3                0.00           M             M  \n",
       "4               40.00           M             M  \n",
       "...               ...         ...           ...  \n",
       "392131              M        0.03           -RA  \n",
       "392132              M        0.02           -RA  \n",
       "392133              M        0.04         RA BR  \n",
       "392134              M        0.05         RA BR  \n",
       "392135              M        0.09         RA BR  \n",
       "\n",
       "[392136 rows x 9 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.v2.csv.gz')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The `station` column indicates the city.  The `time` is measured in UTC.  Both `temp` and `dew_point` are measured in degrees Fahrenheit.  The `wind_speed` is in knots, and the `precip_hour` measures the hourly precipitation in inches.\n",
    "\n",
    "Missing values are indicated by a flag value.  Remove rows without valid temperature measurements.  You may also want to change some data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station', 'time', 'temp', 'dew_point', 'pressure', 'wind_speed',\n",
       "       'wind_direction', 'precip_hour', 'weather_codes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station 0\n",
      "time 0\n",
      "temp 116\n",
      "dew_point 142\n",
      "pressure 4533\n",
      "wind_speed 7330\n",
      "wind_direction 42054\n",
      "precip_hour 86471\n",
      "weather_codes 360028\n"
     ]
    }
   ],
   "source": [
    "for x in df.columns:\n",
    "    print(x, len(df[df[x]=='M']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['time'] = pd.to_datetime(df['time'])\n",
    "# # df[\"a\"] = pd.to_numeric(df[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df['temp']!='M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"temp\"]=  pd.to_numeric(df[\"temp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station 0\n",
      "time 0\n",
      "temp 0\n",
      "dew_point 27\n",
      "pressure 4442\n",
      "wind_speed 7299\n",
      "wind_direction 42004\n",
      "precip_hour 86452\n",
      "weather_codes 359933\n"
     ]
    }
   ],
   "source": [
    "for x in df.columns:\n",
    "    print(x, len(df[df[x]=='M']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We will focus on using the temporal elements to predict the temperature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "For each question, build a model to predict the temperature in a given city at a given time.  You will be given a DataFrame, as we got from `pd.read_csv`.  (As you can imagine, the temperature values will be nonsensical in the DataFrame you are given.)  Return a collection of predicted temperatures, one for each incoming row in the DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 392020 entries, 0 to 392135\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   station         392020 non-null  object \n",
      " 1   time            392020 non-null  object \n",
      " 2   temp            392020 non-null  float64\n",
      " 3   dew_point       392020 non-null  object \n",
      " 4   pressure        392020 non-null  object \n",
      " 5   wind_speed      392020 non-null  object \n",
      " 6   wind_direction  392020 non-null  object \n",
      " 7   precip_hour     392020 non-null  object \n",
      " 8   weather_codes   392020 non-null  object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 29.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## One-city model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "As you may have noticed, the data contains rows for multiple cities.  We'll deal with all of them soon, but for this first question, we'll focus on only the data from New York (`\"NYC\"`).  Start by isolating only those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "df_nyc = df[df['station']=='NYC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station 0\n",
      "time 0\n",
      "temp 0\n",
      "dew_point 27\n",
      "pressure 4442\n",
      "wind_speed 7299\n",
      "wind_direction 42004\n",
      "precip_hour 86452\n",
      "weather_codes 359933\n"
     ]
    }
   ],
   "source": [
    "for x in df_nyc.columns:\n",
    "    print(x, len(df[df[x]=='M']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Seasonal features are nice because they are relatively safe to extrapolate into the future. There are two ways to handle seasonality.  \n",
    "\n",
    "The simplest (and perhaps most robust) is to have a set of indicator variables. That is, make the assumption that the temperature at any given time is a function of only the month of the year and the hour of the day, and use that to predict the temperature value.\n",
    "\n",
    "**Question**: Should month be a continuous or categorical variable?  (Recall that [one-hot encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) is useful to deal with categorical variables.)\n",
    "\n",
    "Build a model to predict the temperature for a given hour in a given month in New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.to_numeric(df_nyc['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class ConvertDateTemp(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X.loc[:,'time'] = pd.to_datetime(X['time'])\n",
    "#         if 'temp' in X.columns:\n",
    "#             X.loc[:,'temp'] =  pd.to_numeric(X[\"temp\"])\n",
    "        return  X\n",
    "    \n",
    "convert_date_temp = ConvertDateTemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonthHourExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # X will be a pandas series. Return a pandas series of dictionaries\n",
    "        return pd.DataFrame([[i.month,i.hour] for i in X.squeeze()])\n",
    "    \n",
    "    \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "selector = ColumnTransformer([\n",
    "    ('time_temp', MonthHourExtractor(), ['time'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nyc[['time','temp']].set_index('time').plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(2, 15)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(2,15,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "r_f_regressor = RandomForestRegressor()\n",
    " \n",
    "# max_depth_range = range(3,100,5)\n",
    "# min_samples_split_range= range(200,1000,50)\n",
    "# parameters = {'max_depth': max_depth_range,'min_samples_split' : min_samples_split_range}\n",
    "# dt = DecisionTreeRegressor()\n",
    "# dt_grid = GridSearchCV(dt, parameters, verbose=3)\n",
    "\n",
    "# one_hot = OneHotEncoder()\n",
    "\n",
    "# n_alphas = 50\n",
    "# alphas = np.logspace(-10, 3, n_alphas)\n",
    "\n",
    "# parameters = {'alpha': alphas}\n",
    "# ridge_ = Ridge()\n",
    "# ridge_grid = GridSearchCV(ridge_, parameters, verbose=3)\n",
    "\n",
    "\n",
    "predict_temp = Pipeline([\n",
    "        ('convert_date_temp',convert_date_temp),\n",
    "        ('selector',selector),\n",
    "#         ('one_hot', one_hot),## not needed\n",
    "#         ('dt_grid',dt_grid) \n",
    "        ('ran_forest_regressot', RandomForestRegressor())## RandomForestRegressor will also yeild same results\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.5s\n",
      "[Pipeline]  (step 3 of 3) Processing ran_forest_regressot, total=   1.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('convert_date_temp', ConvertDateTemp()),\n",
       "                ('selector',\n",
       "                 ColumnTransformer(transformers=[('time_temp',\n",
       "                                                  MonthHourExtractor(),\n",
       "                                                  ['time'])])),\n",
       "                ('ran_forest_regressot', RandomForestRegressor())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_temp.fit(df_nyc, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_temp['dt_grid'].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        33.910696\n",
       "1        33.411322\n",
       "2        32.923107\n",
       "3        32.567538\n",
       "4        32.133810\n",
       "           ...    \n",
       "77740    42.978126\n",
       "77741    42.551293\n",
       "77742    41.787184\n",
       "77743    41.462448\n",
       "77744    41.071648\n",
       "Length: 77745, dtype: float64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predict_temp.predict(df_nyc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Per-city model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now we want to extend this same model to handle all of the cities in our data set.  Rather than adding features to the existing model to handle this, we'll just make a new copy of the model for each city.\n",
    "\n",
    "If your model is a single class, then this is easy&mdash;you can just instantiate your class once per city.  But it's more likely your model was a particular instance of a Pipeline.  If that's the case, make a **factory function** that returns a new copy of that Pipeline each time it's called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def season_factory():\n",
    "    return Pipeline([\n",
    "        ('convert_date_temp',convert_date_temp),\n",
    "        ('selector',selector),\n",
    "#         ('one_hot', one_hot),## not needed\n",
    "#         ('dt_grid',dt_grid) \n",
    "        ('ran_forest_regressot', RandomForestRegressor())## RandomForestRegressor will also yeild same results\n",
    "], verbose=True) # A single estimator or a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Calling this function should give a new copy of the Pipeline.  If we train that new copy on the New York data, it should give us the same model as before. \n",
    "\n",
    "While we could manually call this function for each city in our dataset, let's build a \"group-by\" estimator that does this for us.  This estimator should take a column name and a factory function as an argument.  The `fit` method will group the incoming data by that column, and for each group it will call the factory to create a new instance to be trained by on that group.  Then, the `predict` method should look up the corresponding model for each row and perform a predict using that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "# from sklearn import base\n",
    "# import pandas as pd \n",
    "# import datetime\n",
    "# import numpy as np\n",
    "# class GroupbyEstimator(base.BaseEstimator, base.RegressorMixin):\n",
    "    \n",
    "#     def __init__(self, column, estimator_factory):\n",
    "#         self.column = column\n",
    "#         self.estimator_factory = estimator_factory\n",
    "#         self.estimators ={}\n",
    "#         # column is the value to group by; estimator_factory can be\n",
    "#         # called to produce estimators\n",
    "    \n",
    "#     def fit(self, X, y):\n",
    "#         X['time'] = pd.to_datetime(X['time'])\n",
    "#         X['month'] = X['time'].dt.month\n",
    "#         X['hour'] = X['time'].dt.hour\n",
    "#         y =  pd.to_numeric(y)\n",
    "        \n",
    "#         groups = X[self.column].unique()\n",
    "#         for i in groups:\n",
    "#             slicer = X[self.column] == i\n",
    "#             X_i = X[slicer][['month','hour']]\n",
    "#             y_i = y[X[self.column] == i]\n",
    "#             self.estimators[i] = self.estimator_factory().fit(X_i,y_i)\n",
    "#         # Create an estimator and fit it with the portion in each group\n",
    "#         return self\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         X['time'] = pd.to_datetime(X['time'])\n",
    "#         X['month'] = X['time'].dt.month\n",
    "#         X['hour'] = X['time'].dt.hour\n",
    "#         # Call the appropriate predict method for each row of X\n",
    "        \n",
    "#         predictions = X.apply(lambda row : self.estimators[row[self.column]].predict(np.array([row['month'],row['hour']]).reshape(1, -1)), axis = 1)\n",
    "# #         predictions = []\n",
    "# #         for i, row in X.iterrows():\n",
    "# #             identifier = row[self.column]\n",
    "# #             predictions.append(self.estimators[identifier].predict([[row['month'],row['hour']]]))\n",
    "#         return [int(i) for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "import pandas as pd \n",
    "import datetime\n",
    "import numpy as np\n",
    "class GroupbyEstimator(base.BaseEstimator, base.RegressorMixin):\n",
    "    \n",
    "    def __init__(self, column, estimator_factory):\n",
    "        self.column = column\n",
    "        self.estimator_factory = estimator_factory\n",
    "        self.estimators ={}\n",
    "        # column is the value to group by; estimator_factory can be\n",
    "        # called to produce estimators\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y =  pd.to_numeric(y)\n",
    "        \n",
    "        groups = X[self.column].unique()\n",
    "        for i in groups:\n",
    "            slicer = X[self.column] == i\n",
    "            X_i = X[slicer]\n",
    "            y_i = y[slicer]\n",
    "            self.estimators[i] = self.estimator_factory().fit(X_i,y_i)\n",
    "        # Create an estimator and fit it with the portion in each group\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Call the appropriate predict method for each row of X\n",
    "        index_ = []\n",
    "        predictions = []\n",
    "        groups = X[self.column].unique()\n",
    "        X = X.reset_index()\n",
    "        for i in groups:\n",
    "            slicer = X[self.column] == i\n",
    "            X_i = X[slicer]\n",
    "            pred = list(self.estimators[i].predict(X_i))\n",
    "            index_.extend(list(X_i.index))\n",
    "            predictions.extend(pred)\n",
    "        total_prediction = pd.DataFrame({'id': index_, 'pred': predictions }).sort_values('id')\n",
    "\n",
    "        return np.array(total_prediction['pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now, we should be able to build an equivalent model for each city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.5s\n",
      "[Pipeline]  (step 3 of 3) Processing ran_forest_regressot, total=   1.6s\n",
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.1s\n",
      "[Pipeline]  (step 3 of 3) Processing ran_forest_regressot, total=   1.6s\n",
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.5s\n",
      "[Pipeline]  (step 3 of 3) Processing ran_forest_regressot, total=   1.7s\n",
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.1s\n",
      "[Pipeline]  (step 3 of 3) Processing ran_forest_regressot, total=   1.6s\n",
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.5s\n",
      "[Pipeline]  (step 3 of 3) Processing ran_forest_regressot, total=   1.6s\n"
     ]
    }
   ],
   "source": [
    "season_model = GroupbyEstimator('station', season_factory).fit(df, df['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th>temp</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>precip_hour</th>\n",
       "      <th>weather_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2010-01-01 01:51</td>\n",
       "      <td>60.08</td>\n",
       "      <td>17.96</td>\n",
       "      <td>1025.30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2010-01-01 02:51</td>\n",
       "      <td>59.00</td>\n",
       "      <td>17.96</td>\n",
       "      <td>1025.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2010-01-01 03:51</td>\n",
       "      <td>53.96</td>\n",
       "      <td>21.92</td>\n",
       "      <td>1026.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392133</th>\n",
       "      <td>NYC</td>\n",
       "      <td>2018-12-31 21:51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>39.90</td>\n",
       "      <td>1021.60</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.04</td>\n",
       "      <td>RA BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392132</th>\n",
       "      <td>NYC</td>\n",
       "      <td>2018-12-31 20:51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>37.90</td>\n",
       "      <td>1023.40</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392131</th>\n",
       "      <td>NYC</td>\n",
       "      <td>2018-12-31 19:51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>37.90</td>\n",
       "      <td>1024.10</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2010-01-01 04:51</td>\n",
       "      <td>55.94</td>\n",
       "      <td>17.06</td>\n",
       "      <td>1026.20</td>\n",
       "      <td>5.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2010-01-01 05:51</td>\n",
       "      <td>53.06</td>\n",
       "      <td>17.06</td>\n",
       "      <td>1026.20</td>\n",
       "      <td>7.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station              time   temp dew_point pressure wind_speed  \\\n",
       "1          PHX  2010-01-01 01:51  60.08     17.96  1025.30       4.00   \n",
       "2          PHX  2010-01-01 02:51  59.00     17.96  1025.60       4.00   \n",
       "3          PHX  2010-01-01 03:51  53.96     21.92  1026.00       0.00   \n",
       "392133     NYC  2018-12-31 21:51  43.00     39.90  1021.60          M   \n",
       "392132     NYC  2018-12-31 20:51  43.00     37.90  1023.40          M   \n",
       "392131     NYC  2018-12-31 19:51  43.00     37.90  1024.10          M   \n",
       "4          PHX  2010-01-01 04:51  55.94     17.06  1026.20       5.00   \n",
       "5          PHX  2010-01-01 05:51  53.06     17.06  1026.20       7.00   \n",
       "\n",
       "       wind_direction precip_hour weather_codes  \n",
       "1               50.00           M             M  \n",
       "2               30.00           M             M  \n",
       "3                0.00           M             M  \n",
       "392133              M        0.04         RA BR  \n",
       "392132              M        0.02           -RA  \n",
       "392131              M        0.03           -RA  \n",
       "4               40.00           M             M  \n",
       "5               50.00           M             M  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[ np.r_[ 1,2,3, 392133,392132,392131, 4, 5],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Submit the same model again to the following scorer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "If you passed, congratulations&mdash;you avoided a common pitfall!  Move on to the next question.\n",
    "\n",
    "But if your model suddenly behaved worse: In the previous question, we provided each city's rows in contiguous groups.  In this question, the rows were all shuffled together.  If you were predicting for a group at a time and just appending those grouped predictions for the final output, it'll be in the wrong order.\n",
    "\n",
    "There are two ways to fix this:\n",
    "1. Predict for each row individually.  This is straightforward, but very, _very_ slow.\n",
    "2. Predict for each group, and then reorder the predictions to match the input order.  A common way to do this is to attach the index of the feature matrix to the predictions, and then order the full prediction series by the index of the feature matrix.\n",
    "\n",
    "Once you've fixed your `GroupbyEstimator.predict` method, resubmit to this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Fourier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Let's consider another way to deal with the seasonal terms.  Since we know that temperature is roughly sinusoidal, we know that a reasonable model might be\n",
    "\n",
    "$$ y_t = y_0 \\sin\\left(2\\pi\\frac{t - t_0}{T}\\right) + \\epsilon $$\n",
    "\n",
    "where $y_0$ and $t_0$ are parameters to be learned and $T$ is the period - one year for seasonal variation, one day for daily, etc.  While this is linear in $y_0$, it is not linear in $t_0$. However, we know from Fourier analysis, that the above is\n",
    "equivalent to\n",
    "\n",
    "$$ y_t = A \\sin\\left(2\\pi\\frac{t}{T}\\right) + B \\cos\\left(2\\pi\\frac{t}{T}\\right) + \\epsilon $$\n",
    "\n",
    "which is linear in $A$ and $B$.\n",
    "\n",
    "Create a model containing sinusoidal terms on one or more time scales, and fit it to the data using a linear regression.  Build a `fourier_factory` function that will return instances of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2455197.53541667, 2455197.57708333, 2455197.61875   , ...,\n",
       "       2458484.41041667, 2458484.45208333, 2458484.49375   ])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pd.DatetimeIndex(df['time']).to_julian_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class ConvertDateTemp(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['time'] = pd.to_datetime(X['time'])\n",
    "        X['Julian'] = np.array(pd.DatetimeIndex(X['time']).to_julian_date())\n",
    "        X['const'] = 1\n",
    "        X['sin_year'] = np.sin(X['Julian'] / 365.25 * 2 * np.pi)\n",
    "        X['cos_year'] = np.cos(X['Julian'] / 365.25 * 2 * np.pi)\n",
    "        X['sin_6mo'] = np.sin(X['Julian'] / (365.25 / 2) * 2 * np.pi)\n",
    "        X['cos_6mo'] = np.cos(X['Julian'] / (365.25 / 2) * 2 * np.pi)\n",
    "        X['sin_day'] = np.sin(X['time'].dt.hour / 24.0 * 2* np.pi)\n",
    "        X['cos_day'] = np.cos(X['time'].dt.hour / 24.0 * 2* np.pi)\n",
    "        return  X\n",
    "    \n",
    "convert_date_temp = ConvertDateTemp()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station', 'time', 'temp', 'dew_point', 'pressure', 'wind_speed',\n",
       "       'wind_direction', 'precip_hour', 'weather_codes', 'Julian', 'const',\n",
       "       'sin_year', 'cos_year', 'sin_6mo', 'cos_6mo', 'sin_day', 'cos_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_date_temp.fit_transform(df).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MonthHourExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "# #         temps['Julian'] = np.array(pd.DatetimeIndex(df['time']).to_julian_date())\n",
    "# #         temps['const'] = 1\n",
    "# #         temps['sin(year)'] = np.sin(temps['Julian'] / 365.25 * 2 * np.pi)\n",
    "# #         temps['cos(year)'] = np.cos(temps['Julian'] / 365.25 * 2 * np.pi)\n",
    "# #         temps['sin(6mo)'] = np.sin(temps['Julian'] / (365.25 / 2) * 2 * np.pi)\n",
    "# #         temps['cos(6mo)'] = np.cos(temps['Julian'] / (365.25 / 2) * 2 * np.pi)\n",
    "# #         temps['sin(day)'] = np.sin(temps.index.hour / 24.0 * 2* np.pi)\n",
    "# #         temps['cos(day)'] = np.cos(temps.index.hour / 24.0 * 2* np.pi)\n",
    "        \n",
    "        \n",
    "#         return X.to_julian_date()#pd.DataFrame([[i.month,i.hour] for i in X.squeeze()])\n",
    "    \n",
    "    \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "selector = ColumnTransformer([\n",
    "    ('time_temp','passthrough', ['sin_year', 'cos_year', 'sin_6mo', 'cos_6mo', 'sin_day', 'cos_day']) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22117804,  0.97523345, -0.43140044,  0.90216055,  0.        ,\n",
       "         1.        ],\n",
       "       [-0.22047896,  0.97539173, -0.43010671,  0.90277805,  0.25881905,\n",
       "         0.96592583],\n",
       "       [-0.21977978,  0.97554951, -0.42881211,  0.9033937 ,  0.5       ,\n",
       "         0.8660254 ],\n",
       "       ...,\n",
       "       [-0.22746453,  0.97378637, -0.44300372,  0.89651977, -0.70710678,\n",
       "         0.70710678],\n",
       "       [-0.22676649,  0.97394916, -0.44171807,  0.89715391, -0.5       ,\n",
       "         0.8660254 ],\n",
       "       [-0.22606834,  0.97411144, -0.44043152,  0.89778621, -0.25881905,\n",
       "         0.96592583]])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.fit_transform(convert_date_temp.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "predict_temp = Pipeline([\n",
    "        ('convert_date_temp',convert_date_temp),\n",
    "        ('selector',selector),\n",
    "#         ('one_hot', one_hot),## not needed\n",
    "#         ('dt_grid',dt_grid) \n",
    "        ('l_regressor', LinearRegression())## RandomForestRegressor will also yeild same results\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "def fourier_factory():\n",
    "    return Pipeline([\n",
    "        ('convert_date_temp',convert_date_temp),\n",
    "        ('selector',selector),\n",
    "#         ('one_hot', one_hot),## not needed\n",
    "#         ('dt_grid',dt_grid) \n",
    "        ('l_regressor', LinearRegression())## RandomForestRegressor will also yeild same results\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "A general `GroupByEstimator` should be able to take the new factory function and build a model for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.1s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 3) Processing l_regressor, total=   0.0s\n",
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 3) Processing l_regressor, total=   0.0s\n",
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 3) Processing l_regressor, total=   0.0s\n",
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 3) Processing l_regressor, total=   0.0s\n",
      "[Pipeline] . (step 1 of 3) Processing convert_date_temp, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 3) Processing l_regressor, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "fourier_model = GroupbyEstimator('station', fourier_factory).fit(df, df['temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "*Copyright &copy; 2022 Pragmatic Institute. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbclean": true,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
